{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9917,"status":"ok","timestamp":1700454664959,"user":{"displayName":"Kejia Zhang","userId":"18337919774296652596"},"user_tz":-480},"id":"hmz95WbOkaxE"},"outputs":[],"source":["from matplotlib.pyplot import xlabel\n","import torch\n","import h5py\n","import numpy as np\n","import networkx as nx\n","import scipy.sparse as sp\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch_geometric.utils import to_undirected\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from ast import Num\n","from turtle import pd\n","from matplotlib.pyplot import xlabel\n","import torch\n","import h5py\n","import pdb\n","import numpy as np\n","import networkx as nx\n","import scipy.sparse as sp\n","import pandas as pd\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch_geometric.nn import GCNConv,GATConv,GATv2Conv,SAGEConv\n","from torch_geometric.data import Data\n","from torch_geometric.utils import degree\n","from torch_geometric.utils import negative_sampling,get_laplacian\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":852,"status":"ok","timestamp":1700454665809,"user":{"displayName":"Kejia Zhang","userId":"18337919774296652596"},"user_tz":-480},"id":"eFzbSy3IlOss","outputId":"df32139b-e9d5-44fc-d295-abf6762c4645"},"outputs":[],"source":["torch.set_default_tensor_type(torch.DoubleTensor)\n","\n","class SAGE(nn.Module):\n","    def __init__(self, graph, label):\n","      super(SAGE, self).__init__()\n","      self.graph = graph\n","      self.label = label  #One_hot label\n","      self.num_nodes = graph.num_nodes\n","      self.edges = graph[\"edge_index\"]\n","      self.in_c = 128\n","      self.hid_c = 64\n","      self.out_c = np.size(label,1)\n","      self.loss_function = nn.BCELoss()\n","\n","      self.linear = nn.Linear(self.num_nodes, self.in_c)\n","      self.gcn1 = SAGEConv(self.in_c, self.hid_c)\n","      self.gcn2 = SAGEConv(self.hid_c, self.out_c)\n","\n","    def forward(self):\n","      ini_feature ,edge_index = self.graph[\"x\"],self.graph[\"edge_index\"]\n","      # ini_feature = ini_feature.to(torch.float32)\n","      x = torch.relu(self.linear(ini_feature))\n","      x = torch.relu(self.gcn1(x, edge_index))\n","      x = self.gcn2(x, edge_index)\n","\n","      return F.log_softmax(x, dim=1)\n","\n","class GCN(nn.Module):\n","    def __init__(self, graph, label):\n","        super(GCN, self).__init__()\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = graph[\"edge_index\"]\n","        self.in_c = 128*2\n","        self.hid_c = 64\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn2 = GCNConv(self.hid_c, self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index = self.graph[\"x\"],self.graph[\"edge_index\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x = torch.relu(self.gcn1(x, edge_index))\n","        x = self.gcn2(x, edge_index)\n","\n","        return F.log_softmax(x, dim=1)\n","\n","class GAT(nn.Module):\n","    def __init__(self, graph, label):\n","        super(GAT, self).__init__()\n","        self.graph = graph\n","        self.label = label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = graph[\"edge_index\"]\n","        self.in_c = 128*2\n","        self.hid_c = 64\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GATConv(self.in_c, self.hid_c)\n","        self.gcn2 = GATConv(self.hid_c, self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index = self.graph[\"x\"],self.graph[\"edge_index\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x = torch.relu(self.gcn1(x, edge_index))\n","        x = self.gcn2(x, edge_index)\n","\n","        return F.log_softmax(x, dim=1)\n","\n","class MLP(nn.Module):\n","    def __init__(self, graph, label):\n","        super(MLP, self).__init__()\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = graph[\"edge_index\"]\n","        self.in_c = 128*2\n","        self.hid_c = 64\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = nn.Linear(self.in_c, self.hid_c)\n","        self.gcn2 = nn.Linear(self.hid_c, self.out_c)\n","\n","    def forward(self):\n","        ini_feature = self.graph[\"x\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x = torch.relu(self.gcn1(x))\n","        x = self.gcn2(x)\n","\n","        return F.log_softmax(x, dim=1)\n","\n","class MGCN(nn.Module):\n","    def __init__(self, graph, label):\n","        super(MGCN, self).__init__()\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = graph[\"edge_index\"]\n","        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n","        self.in_c = 128*2\n","        self.hid_c = 64\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn2 = GCNConv(self.hid_c, self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index,motif_W = self.graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x = torch.relu(self.gcn1(x, edge_index,edge_weight=motif_W))\n","        x = self.gcn2(x, edge_index,edge_weight=motif_W)\n","\n","        return F.log_softmax(x, dim=1)\n","\n","class DGCN(nn.Module):\n","    def __init__(self, sim_graph,graph, label, cat_method = 'mlp',dropout=0):\n","        super(DGCN, self).__init__()\n","        self.sim_graph = sim_graph\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = sim_graph[\"edge_index\"]\n","        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n","        self.in_c = 128\n","        self.hid_c = 64\n","        self.hid_c2 = 32\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","        self.cat_method = cat_method\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn2 = GCNConv(self.hid_c,self.hid_c2)\n","        self.gcn3 = GCNConv(self.hid_c2, self.hid_c2*2)\n","        self.gcn4 = GCNConv(self.hid_c2*2, self.hid_c2)\n","        self.mlp = nn.Linear(self.hid_c2*2, self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index,motif_W = self.sim_graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n","        edge_index_sim= self.sim_graph[\"edge_index\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x = self.dropout(x)\n","        x1 = torch.relu(self.gcn1(x, edge_index_sim))\n","        x1 = self.dropout(x1)\n","        x2 = torch.relu(self.gcn2(x1, edge_index_sim))\n","        x2 = self.dropout(x2)\n","        x3 = torch.relu(self.gcn3(x2, edge_index,edge_weight=motif_W))\n","        x3 = self.dropout(x3)\n","        x4 = torch.relu(self.gcn4(x3, edge_index,edge_weight=motif_W))\n","        x4 = self.dropout(x4)\n","        x_out = torch.cat((x2,x4),1)\n","        x_out_nc = self.mlp(x_out)\n","        return F.log_softmax(x_out_nc, dim=1)\n","\n","class DGCN1(nn.Module):\n","    def __init__(self, sim_graph,graph, label):\n","        super(DGCN1, self).__init__()\n","        self.sim_graph = sim_graph\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = sim_graph[\"edge_index\"]\n","        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n","        self.in_c = 128\n","        self.hid_c = 64\n","        self.hid_c2 = 32\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn2 = GCNConv(self.hid_c,self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index,motif_W = self.sim_graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n","        edge_index_sim= self.sim_graph[\"edge_index\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x1 = torch.relu(self.gcn1(x, edge_index,edge_weight=motif_W))\n","        x2 = torch.relu(self.gcn2(x1, edge_index,edge_weight=motif_W))\n","        return F.log_softmax(x2, dim=1)\n","\n","class DGCN3(nn.Module):\n","    def __init__(self, sim_graph,graph, label):\n","        super(DGCN3, self).__init__()\n","        self.sim_graph = sim_graph\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = sim_graph[\"edge_index\"]\n","        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n","        self.in_c = 128\n","        self.hid_c = 64\n","        self.hid_c2 = 32\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss() \n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn2 = GCNConv(self.hid_c,self.hid_c2)\n","        self.gcn3 = GCNConv(self.hid_c2, self.hid_c2*2)\n","        self.gcn4 = GCNConv(self.hid_c2*2, self.hid_c2)\n","        self.mlp = nn.Linear(self.hid_c2*2, self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index,motif_W = self.sim_graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n","        edge_index_sim= self.sim_graph[\"edge_index\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x1 = torch.relu(self.gcn1(x, edge_index,edge_weight=motif_W))\n","        x2 = torch.relu(self.gcn2(x1, edge_index,edge_weight=motif_W))\n","        x3 = torch.relu(self.gcn3(x2, edge_index,edge_weight=motif_W))\n","        x4 = torch.relu(self.gcn4(x3, edge_index,edge_weight=motif_W))\n","        x_out = torch.cat((x2,x4),1)\n","        x_out_nc = self.mlp(x_out)\n","        return F.log_softmax(x_out_nc, dim=1)\n","\n","class DGCN2(nn.Module):\n","    def __init__(self, sim_graph,graph, label):\n","        super(DGCN2, self).__init__()\n","        self.sim_graph = sim_graph\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = sim_graph[\"edge_index\"]\n","        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n","        self.in_c = 128\n","        self.hid_c = 64\n","        self.hid_c2 = 32\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn2 = GCNConv(self.hid_c,self.hid_c2)\n","        self.gcn3 = GCNConv(self.hid_c2, self.hid_c2*2)\n","        self.gcn4 = GCNConv(self.hid_c2*2, self.hid_c2)\n","        self.mlp = nn.Linear(self.hid_c2*2, self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index,motif_W = self.sim_graph[\"x\"],self.sim_graph[\"edge_index\"],self.graph[\"edge_attr\"]\n","        edge_index_sim= self.sim_graph[\"edge_index\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x1 = torch.relu(self.gcn1(x, edge_index))\n","        x2 = torch.relu(self.gcn2(x1, edge_index))\n","        x3 = torch.relu(self.gcn3(x2, edge_index))\n","        x4 = torch.relu(self.gcn4(x3, edge_index))\n","        x_out = torch.cat((x2,x4),1)\n","        x_out_nc = self.mlp(x_out)\n","        return F.log_softmax(x_out_nc, dim=1)\n","\n","class DGCN4(nn.Module):\n","    def __init__(self, sim_graph, graph, label):\n","        super(DGCN4, self).__init__()\n","        self.sim_graph = sim_graph\n","        self.graph = graph\n","        self.label = label  #One_hot label\n","        self.num_nodes = graph.num_nodes\n","        self.edges = sim_graph[\"edge_index\"]\n","        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n","        self.in_c = 128\n","        self.hid_c = 64\n","        self.hid_c2 = 32\n","        self.out_c = np.size(label,1)\n","        self.loss_function = nn.BCELoss()\n","\n","        self.linear = nn.Linear(self.num_nodes, self.in_c)\n","        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn2 = GCNConv(self.hid_c,self.hid_c2)\n","        self.gcn3 = GCNConv(self.in_c, self.hid_c)\n","        self.gcn4 = GCNConv(self.hid_c, self.hid_c2)\n","        self.mlp = nn.Linear(self.hid_c2*2, self.out_c)\n","\n","    def forward(self):\n","        ini_feature ,edge_index,motif_W = self.sim_graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n","        edge_index_sim= self.sim_graph[\"edge_index\"]\n","        # ini_feature = ini_feature.to(torch.float32)\n","        x = torch.relu(self.linear(ini_feature))\n","        x1 = torch.relu(self.gcn1(x, edge_index_sim))\n","        x2 = torch.relu(self.gcn2(x1, edge_index_sim))\n","        x3 = torch.relu(self.gcn3(x, edge_index,edge_weight=motif_W))\n","        x4 = torch.relu(self.gcn4(x3, edge_index,edge_weight=motif_W))\n","        x_out = torch.cat((x2,x4),1)\n","        x_out_nc = self.mlp(x_out)\n","        return F.log_softmax(x_out_nc, dim=1)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700454665809,"user":{"displayName":"Kejia Zhang","userId":"18337919774296652596"},"user_tz":-480},"id":"SNa3qDt0lPbP"},"outputs":[],"source":["def Get_edge_pyg(A):\n","\n","  edge_index_temp = sp.coo_matrix(A)\n","  values = edge_index_temp.data\n","  indices = np.vstack((edge_index_temp.row, edge_index_temp.col))\n","  # edge_index_A = torch.LongTensor(indices)\n","  edge = torch.LongTensor(indices)\n","  edge_attribute = torch.FloatTensor(values)\n","  edge_index = torch.sparse_coo_tensor(edge, edge_attribute, edge_index_temp.shape)\n","  return edge_index, edge, edge_attribute\n","\n","def graph_info(graph):\n","  print(\"Graph Information:\\nnum_nodes:\"+str(graph.num_nodes)+\"  num_edges:\"+str(int(graph.num_edges/2))+\"  is_directed:\"+str(graph.is_directed())+\"\\nnode_att_num:\"+str(graph.num_node_features)+\"  edge_att_num:\"+str(graph.num_edge_features)+\"  isolated_nodes:\"+str(graph.has_isolated_nodes()))\n","  return\n","\n","def One_hot_label(label):\n","  One_hot = np.zeros((len(label), np.max(label)-np.min(label)+1 ))\n","  for i in range(len(label)):\n","      One_hot[i][label[i]]=1\n","  return One_hot\n","\n","def load_mat(feature,name):\n","    mat = feature[str(name)][:]\n","    mat = np.transpose(mat)\n","    mat = torch.tensor(mat)\n","    return mat\n","\n","def Compute_accruracy(out,Label,test_set):\n","  pred = out[test_set].argmax(axis=1)\n","  true = Label[test_set].argmax(axis=1)\n","  correct = int((pred.numpy()==true).sum())\n","  acc = correct / len(test_set)\n","  # print('Accuracy: {:.4f}'.format(acc))\n","  return acc"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7042,"status":"ok","timestamp":1700454672850,"user":{"displayName":"Kejia Zhang","userId":"18337919774296652596"},"user_tz":-480},"id":"z54QttRHGL0W"},"outputs":[],"source":["torch.set_default_tensor_type(torch.DoubleTensor)\n","path = './NC_M3.mat'\n","feature = h5py.File(path)\n","\n","\n","# cora_A = load_mat(feature,'cora_A')\n","#citeseer\n","# cora_A = load_mat(feature,'cora_A')\n","# cora_M32 = load_mat(feature,'cora_M32')\n","# cora_A = load_mat(feature,'citeseer_A')\n","# cora_M32 = load_mat(feature,'citeseer_M32')\n","# cora_A = load_mat(feature,'pumed')\n","# cora_M32 = load_mat(feature,'pumed_M32')\n","# cora_A = load_mat(feature,'flickr_A')\n","# cora_M32 = load_mat(feature,'flickr_M32')\n","\n","\n","cora_A = load_mat(feature,'Blog_A')\n","cora_M32 = load_mat(feature,'Blog_M32')\n","\n","_,edge,_ = Get_edge_pyg(cora_A)\n","_,edge_M32_AW,M32_att_AW = Get_edge_pyg(cora_A+cora_M32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":884,"status":"ok","timestamp":1700455100832,"user":{"displayName":"Kejia Zhang","userId":"18337919774296652596"},"user_tz":-480},"id":"I1l4-Hl6okBM","outputId":"73d97120-7d8a-4ff0-96aa-59f39abf959b"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","test_size = 0.8\n","epochs = 100\n","learning_rate = 0.001\n","seed = 1234\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","path1 = './B_Labels.npy'\n","labels = np.load(path1)\n","Label = One_hot_label(labels)\n","Nodes = list(range(len(labels)))\n","\n","graph_cora = Data(x=torch.tensor(cora_A), edge_index = edge).to(device)\n","graph_cora_M32_AW = Data(x=(cora_A+cora_M32), edge_index = edge_M32_AW, edge_attr = M32_att_AW).to(device)\n","\n","train_set, test_set = train_test_split(Nodes, test_size=test_size, random_state=41)\n","train_label = torch.tensor(labels[train_set])\n","true_label = torch.tensor(labels[test_set])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":471,"status":"ok","timestamp":1700454910497,"user":{"displayName":"Kejia Zhang","userId":"18337919774296652596"},"user_tz":-480},"id":"rUtLm3Gaok6O","outputId":"055e2e7c-3925-4f1e-aadf-d25b3295154e"},"outputs":[],"source":["print(graph_cora.num_nodes)\n","print(true_label.shape)\n","print(train_label.shape)\n","print(Label.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168064,"status":"ok","timestamp":1700455270553,"user":{"displayName":"Kejia Zhang","userId":"18337919774296652596"},"user_tz":-480},"id":"xnbY86Q9lZG4","outputId":"7d7819ae-dd5a-4d73-e8c7-0404b08cda5f"},"outputs":[],"source":["model = MGCN(graph=graph_cora, label = Label).to(device)\n","print(f\"test_size:{test_size}\")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n","model.train()\n","for epoch in range(epochs):\n","  optimizer.zero_grad()\n","  out = model.forward()\n","  pred_label = out[train_set].to(device)\n","  loss = F.nll_loss(input=pred_label.to(device),target=train_label.to(device))\n","  loss.backward()\n","  optimizer.step()\n","model.eval()\n","S = model.forward()\n","acc=Compute_accruracy(S.cpu(),Label,test_set)\n","print(f\"{model}--acc:{acc:.4f}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMLhLNEsV/gphuUVGHT+CJA","mount_file_id":"10KbVH9IFB4UW1V2AvbMC8lsHne3sOP9U","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
