{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmz95WbOkaxE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import h5py\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv,GATConv,GATv2Conv,SAGEConv,TransformerConv,Node2Vec\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import degree\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFzbSy3IlOss"
      },
      "outputs": [],
      "source": [
        "from operator import xor\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "class My_GCN(nn.Module):\n",
        "    def __init__(self, graph):\n",
        "        super(My_GCN, self).__init__()\n",
        "        self.graph = graph\n",
        "        self.num_nodes = graph.num_nodes\n",
        "        self.edges = graph[\"edge_index\"].to(device)\n",
        "        self.in_c = 128\n",
        "        self.hid_c = 256\n",
        "        self.out_c = 128\n",
        "\n",
        "        self.dropout = 0\n",
        "        self.linear = nn.Linear(self.num_nodes, self.in_c)\n",
        "        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n",
        "        self.gcn2 = GCNConv(self.hid_c, self.out_c)\n",
        "\n",
        "    def forward(self):\n",
        "        ini_feature ,edge_index = self.graph[\"x\"].to(device),self.graph[\"edge_index\"].to(device)\n",
        "        x = torch.tanh(self.linear(ini_feature))\n",
        "        x = torch.tanh(self.gcn1(x, edge_index))\n",
        "        x = F.dropout(x,self.dropout)\n",
        "        x = self.gcn2(x, edge_index)\n",
        "        x = F.dropout(x,self.dropout)\n",
        "\n",
        "        return x \n",
        "\n",
        "    def loss(self, after_mapping):\n",
        "        indices1 = self.graph[\"edge_index\"]\n",
        "        source_feats1 = after_mapping[indices1[0].type(torch.long)].to(device)\n",
        "        target_feats1 = after_mapping[indices1[1].type(torch.long)].to(device)\n",
        "        num_sampled= int(self.graph.num_edges/2)\n",
        "        negative_deges = negative_sampling(edge_index=self.edges,num_nodes=self.graph.num_nodes,num_neg_samples=num_sampled)\n",
        "        negative_src = torch.tensor(negative_deges[0])\n",
        "        negative_trg = torch.tensor(negative_deges[1])\n",
        "        source_feats3 = after_mapping[negative_src.type(torch.long)].to(device)\n",
        "        target_feats3 = after_mapping[negative_trg.type(torch.long)].to(device)\n",
        "\n",
        "        dots_1= torch.sum(torch.mul(source_feats1,target_feats1), dim=1)\n",
        "        dots1_loss = torch.mean(-1.0 * F.logsigmoid(dots_1))\n",
        "        dots_3= torch.sum(torch.mul(source_feats3,target_feats3), dim=1)\n",
        "        dots3_loss = torch.mean(-1.0 * torch.log(1.000001 - torch.sigmoid(dots_3)))\n",
        "\n",
        "        mapping_loss = dots1_loss + dots3_loss\n",
        "        return mapping_loss, dots1_loss, dots3_loss\n",
        "\n",
        "class DGCN(nn.Module):\n",
        "    def __init__(self, sim_graph,graph,dropout):\n",
        "        super(DGCN, self).__init__()\n",
        "        self.sim_graph = sim_graph\n",
        "        self.graph = graph\n",
        "        self.num_nodes = graph.num_nodes\n",
        "        self.edges = sim_graph[\"edge_index\"]\n",
        "        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n",
        "        self.in_c = 128\n",
        "        self.hid_c = 128*2\n",
        "        self.out_c = 64*2\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.linear = nn.Linear(self.num_nodes, self.in_c)\n",
        "        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n",
        "        self.gcn2 = GCNConv(self.hid_c,self.out_c)\n",
        "        self.gcn3 = GCNConv(self.out_c, self.hid_c)\n",
        "        self.gcn4 = GCNConv(self.hid_c, self.out_c)\n",
        "        self.dcn = GCNConv(self.out_c*2,self.out_c)\n",
        "        self.mlp = nn.Linear(self.out_c*2, self.out_c*2)\n",
        "\n",
        "    def forward(self):\n",
        "        ini_feature ,edge_index,motif_W = self.graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n",
        "        edge_index_sim= self.sim_graph[\"edge_index\"]\n",
        "        x = torch.tanh(self.linear(ini_feature.to(torch.double)))\n",
        "        x1 = torch.tanh(self.gcn1(x, edge_index_sim))\n",
        "        x1 = F.dropout(x1,self.dropout)\n",
        "        x2 = torch.tanh(self.gcn2(x1, edge_index_sim))\n",
        "        x2 = F.dropout(x2,self.dropout)\n",
        "        x3 = torch.tanh(self.gcn3(x2, edge_index,edge_weight=motif_W))\n",
        "        x3 = F.dropout(x3,self.dropout)\n",
        "        x4 = torch.tanh(self.gcn4(x3, edge_index,edge_weight=motif_W))\n",
        "        x4 = F.dropout(x4,self.dropout)\n",
        "        x_out = torch.cat((x2,x4),1)\n",
        "        x_out_nc = self.mlp(x_out)\n",
        "        return x_out_nc\n",
        "\n",
        "\n",
        "    def loss(self, after_mapping):\n",
        "        indices1 = self.graph[\"edge_index\"]\n",
        "        source_feats1 = after_mapping[indices1[0].type(torch.long)].to(device)\n",
        "        target_feats1 = after_mapping[indices1[1].type(torch.long)].to(device)\n",
        "        num_sampled= int(self.graph.num_edges/2)\n",
        "        negative_deges = negative_sampling(edge_index=self.edges,num_nodes=self.graph.num_nodes,num_neg_samples=num_sampled)\n",
        "        negative_src = torch.tensor(negative_deges[0])\n",
        "        negative_trg = torch.tensor(negative_deges[1])\n",
        "        source_feats3 = after_mapping[negative_src.type(torch.long)].to(device)\n",
        "        target_feats3 = after_mapping[negative_trg.type(torch.long)].to(device)\n",
        "\n",
        "        dots_1= torch.sum(torch.mul(source_feats1,target_feats1), dim=1)\n",
        "        dots1_loss = torch.mean(-1.0 * F.logsigmoid(dots_1))\n",
        "        dots_3= torch.sum(torch.mul(source_feats3,target_feats3), dim=1)\n",
        "        dots3_loss = torch.mean(-1.0 * torch.log(1.00001 - torch.sigmoid(dots_3)))\n",
        "\n",
        "        mapping_loss = dots1_loss + dots3_loss\n",
        "        return mapping_loss, dots1_loss, dots3_loss\n",
        "\n",
        "class DGCN1(nn.Module):\n",
        "    def __init__(self, sim_graph,graph,dropout):\n",
        "        super(DGCN1, self).__init__()\n",
        "        self.sim_graph = sim_graph\n",
        "        self.graph = graph\n",
        "        self.num_nodes = graph.num_nodes\n",
        "        self.edges = sim_graph[\"edge_index\"]\n",
        "        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n",
        "        self.in_c = 128\n",
        "        self.hid_c = 256\n",
        "        self.out_c = 128\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.linear = nn.Linear(self.num_nodes, self.in_c)\n",
        "        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n",
        "        self.gcn2 = GCNConv(self.hid_c,self.out_c)\n",
        "        self.gcn3 = GCNConv(self.out_c, self.hid_c)\n",
        "        self.gcn4 = GCNConv(self.hid_c, self.out_c)\n",
        "        self.dcn = GCNConv(self.out_c*2,self.out_c)\n",
        "        self.mlp = nn.Linear(self.out_c*2, self.out_c*2)\n",
        "\n",
        "    def forward(self):\n",
        "        ini_feature ,edge_index,motif_W = self.graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n",
        "        edge_index_sim= self.sim_graph[\"edge_index\"]\n",
        "        x = torch.tanh(self.linear(ini_feature.to(torch.double)))\n",
        "        x1 = torch.tanh(self.gcn1(x, edge_index_sim))\n",
        "        x1 = F.dropout(x1,self.dropout)\n",
        "        x2 = torch.tanh(self.gcn2(x1, edge_index_sim))\n",
        "        x2 = F.dropout(x2,self.dropout)\n",
        "        x3 = torch.tanh(self.gcn3(x2, edge_index,edge_weight=motif_W))\n",
        "        x3 = F.dropout(x3,self.dropout)\n",
        "        x4 = torch.tanh(self.gcn4(x3, edge_index,edge_weight=motif_W))\n",
        "        x4 = F.dropout(x4,self.dropout)\n",
        "        x_out = torch.cat((x2,x4),1)\n",
        "        x_out_nc = self.mlp(x_out)\n",
        "        return x_out_nc\n",
        "\n",
        "\n",
        "    def loss(self, after_mapping):\n",
        "        indices1 = self.graph[\"edge_index\"]\n",
        "        source_feats1 = after_mapping[indices1[0].type(torch.long)].to(device)\n",
        "        target_feats1 = after_mapping[indices1[1].type(torch.long)].to(device)\n",
        "        num_sampled= int(self.graph.num_edges/2)\n",
        "        negative_deges = negative_sampling(edge_index=self.edges,num_nodes=self.graph.num_nodes,num_neg_samples=num_sampled)\n",
        "        negative_src = torch.tensor(negative_deges[0])\n",
        "        negative_trg = torch.tensor(negative_deges[1])\n",
        "        source_feats3 = after_mapping[negative_src.type(torch.long)].to(device)\n",
        "        target_feats3 = after_mapping[negative_trg.type(torch.long)].to(device)\n",
        "\n",
        "        dots_1= torch.sum(torch.mul(source_feats1,target_feats1), dim=1)\n",
        "        dots1_loss = torch.mean(-1.0 * F.logsigmoid(dots_1))\n",
        "        dots_3= torch.sum(torch.mul(source_feats3,target_feats3), dim=1)\n",
        "        dots3_loss = torch.mean(-1.0 * torch.log(1.00001 - torch.sigmoid(dots_3)))\n",
        "\n",
        "        mapping_loss = dots1_loss + dots3_loss\n",
        "        return mapping_loss, dots1_loss, dots3_loss\n",
        "\n",
        "class MD_GCN(nn.Module):\n",
        "    def __init__(self, sim_graph,graph,dropout):\n",
        "        super(MD_GCN, self).__init__()\n",
        "        self.sim_graph = sim_graph\n",
        "        self.graph = graph\n",
        "        self.num_nodes = graph.num_nodes\n",
        "        self.edges = sim_graph[\"edge_index\"]\n",
        "        self.node_degree = degree(self.graph[\"edge_index\"][0]).t()\n",
        "        self.in_c = 128\n",
        "        self.hid_c = 256\n",
        "        self.out_c = 128\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.linear = nn.Linear(self.num_nodes, self.in_c)\n",
        "        self.gcn1 = GCNConv(self.in_c, self.hid_c)\n",
        "        self.gcn2 = GCNConv(self.hid_c,self.out_c)\n",
        "        self.gcn3 = GCNConv(self.out_c, self.hid_c)\n",
        "        self.gcn4 = GCNConv(self.hid_c, self.out_c)\n",
        "        self.dcn = GCNConv(self.out_c*2,self.out_c)\n",
        "        self.mlp = nn.Linear(self.out_c*2, self.out_c*2)\n",
        "\n",
        "    def forward(self):\n",
        "        ini_feature ,edge_index,motif_W = self.graph[\"x\"],self.graph[\"edge_index\"],self.graph[\"edge_attr\"]\n",
        "        edge_index_sim= self.sim_graph[\"edge_index\"]\n",
        "        x = torch.tanh(self.linear(ini_feature.to(torch.double)))\n",
        "        x1 = torch.tanh(self.gcn1(x, edge_index_sim))\n",
        "        x1 = F.dropout(x1,self.dropout)\n",
        "        x2 = torch.tanh(self.gcn2(x1, edge_index_sim))\n",
        "        x2 = F.dropout(x2,self.dropout)\n",
        "        x3 = torch.tanh(self.gcn3(x2, edge_index,edge_weight=motif_W))\n",
        "        x3 = F.dropout(x3,self.dropout)\n",
        "        x4 = torch.tanh(self.gcn4(x3, edge_index,edge_weight=motif_W))\n",
        "        x4 = F.dropout(x4,self.dropout)\n",
        "        x_out = torch.cat((x2,x4),1)\n",
        "        x_out_nc = self.mlp(x_out)\n",
        "        return x_out_nc\n",
        "\n",
        "\n",
        "    def loss(self, after_mapping):\n",
        "        indices1 = self.graph[\"edge_index\"]\n",
        "        source_feats1 = after_mapping[indices1[0].type(torch.long)].to(device)\n",
        "        target_feats1 = after_mapping[indices1[1].type(torch.long)].to(device)\n",
        "        num_sampled= int(self.graph.num_edges/2)\n",
        "        negative_deges = negative_sampling(edge_index=self.edges,num_nodes=self.graph.num_nodes,num_neg_samples=num_sampled)\n",
        "        negative_src = torch.tensor(negative_deges[0])\n",
        "        negative_trg = torch.tensor(negative_deges[1])\n",
        "        source_feats3 = after_mapping[negative_src.type(torch.long)].to(device)\n",
        "        target_feats3 = after_mapping[negative_trg.type(torch.long)].to(device)\n",
        "\n",
        "        dots_1= torch.sum(torch.mul(source_feats1,target_feats1), dim=1)\n",
        "        dots1_loss = torch.mean(-1.0 * F.logsigmoid(dots_1))\n",
        "        dots_3= torch.sum(torch.mul(source_feats3,target_feats3), dim=1)\n",
        "        dots3_loss = torch.mean(-1.0 * torch.log(1.00001 - torch.sigmoid(dots_3)))\n",
        "\n",
        "        mapping_loss = dots1_loss + dots3_loss\n",
        "        return mapping_loss, dots1_loss, dots3_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Print_precision(S,Test,k=[100,200]):\n",
        "  v = []\n",
        "  for l in k:\n",
        "    value = Precision(S,Test,l)\n",
        "    print(f\"Precision@{l}: {value}\")\n",
        "    v.append(v)\n",
        "  return v\n",
        "\n",
        "def find_zero(A):\n",
        "  Indices = np.where(A==1)\n",
        "  S = np.vstack((Indices[0],Indices[1]))\n",
        "  return S.T\n",
        "\n",
        "def Precision(S,Test,L):\n",
        "  edge_index_temp = sp.coo_matrix(S)\n",
        "  values = edge_index_temp.data\n",
        "  indices = np.vstack((edge_index_temp.row, edge_index_temp.col,values))\n",
        "  S = list(map(list, zip(*indices)))\n",
        "  SS = sorted(S,key=lambda x:x[2],reverse=True)[:L]\n",
        "  Top_L_indices = np.array(SS)[:,0:2]\n",
        "  Test_indices = (find_zero(Test)).tolist()\n",
        "  precision = 0\n",
        "  for i in range(np.size(Top_L_indices,0)):\n",
        "    if(Top_L_indices[i].tolist() in Test_indices):\n",
        "      precision +=1\n",
        "  return precision/L\n",
        "\n",
        "def processing(S,Train):\n",
        "  rows, cols = np.where(Train == 1)\n",
        "  for i in range(len(rows)):\n",
        "    S[rows[i]][cols[i]]=0\n",
        "  return S\n",
        "  \n",
        "def AA(matrix):\n",
        "  S = np.empty_like(matrix)\n",
        "  degree = matrix.sum(axis=1)\n",
        "  for i in range(len(matrix)):\n",
        "    for j in range(len(matrix)):\n",
        "      neighbor = [1 if (matrix[i][k]==1 and matrix[j][k]==1) else 0 for k in range(len(matrix))]\n",
        "      neighbor_index = [i for i,x, in enumerate(neighbor) if x==1]\n",
        "      AA_value = sum([1/math.log(degree[m]) if degree[m]>1 else 0 for m in range(len(neighbor_index))])\n",
        "      S[i][j] = AA_value\n",
        "  return S\n",
        "\n",
        "def LP(matrix,sigma):\n",
        "  S = matrixPow(matrix,2) + sigma*matrixPow(matrix,3)\n",
        "  return S\n",
        "\n",
        "def matrixPow(Matrix,n):\n",
        "    if(type(Matrix)==list):\n",
        "        Matrix=np.array(Matrix)\n",
        "    if(n==1):\n",
        "        return Matrix\n",
        "    else:\n",
        "        return np.matmul(Matrix,matrixPow(Matrix,n-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNa3qDt0lPbP"
      },
      "outputs": [],
      "source": [
        "def Get_edge_pyg(A):\n",
        "  edge_index_temp = sp.coo_matrix(A)\n",
        "  values = edge_index_temp.data\n",
        "  indices = np.vstack((edge_index_temp.row, edge_index_temp.col))\n",
        "  # edge_index_A = torch.LongTensor(indices)\n",
        "  edge = torch.LongTensor(indices)\n",
        "  edge_attribute = torch.FloatTensor(values)\n",
        "  edge_index = torch.sparse_coo_tensor(edge, edge_attribute, edge_index_temp.shape)\n",
        "  return edge_index, edge, edge_attribute\n",
        "\n",
        "def graph_info(graph):\n",
        "  print(\"Graph Information:\\nnum_nodes:\"+str(graph.num_nodes)+\"  num_edges:\"+str(int(graph.num_edges/2))+\"  is_directed:\"+str(graph.is_directed())+\"\\nnode_att_num:\"+str(graph.num_node_features)+\"  edge_att_num:\"+str(graph.num_edge_features)+\"  isolated_nodes:\"+str(graph.has_isolated_nodes()))\n",
        "  return\n",
        "\n",
        "def One_hot_label(label):\n",
        "  One_hot = np.zeros((len(label), np.max(label)-np.min(label)+1 ))\n",
        "  for i in range(len(label)):\n",
        "      One_hot[i][label[i]]=1\n",
        "  return One_hot\n",
        "\n",
        "def load_mat(feature,name):\n",
        "    mat = feature[str(name)][:]\n",
        "    mat = np.transpose(mat)\n",
        "    mat = torch.tensor(mat)\n",
        "    return mat\n",
        "\n",
        "def Compute_accruracy(out,Label,test_set):\n",
        "  pred = out[test_set].argmax(axis=1)\n",
        "  true = Label[test_set].argmax(axis=1)\n",
        "  correct = int((pred.numpy()==true).sum())\n",
        "  acc = correct / len(test_set)\n",
        "  return acc\n",
        "\n",
        "def greedy_match(S):\n",
        "    \"\"\"\n",
        "    :param S: Scores matrix, shape MxN where M is the number of source nodes,\n",
        "        N is the number of target nodes.\n",
        "    :return: A dict, map from source to list of targets.\n",
        "    \"\"\"\n",
        "    S = S.T\n",
        "    m, n = S.shape\n",
        "    x = S.T.flatten()\n",
        "    min_size = min([m,n])\n",
        "    used_rows = np.zeros((m))\n",
        "    used_cols = np.zeros((n))\n",
        "    max_list = np.zeros((min_size))\n",
        "    row = np.zeros((min_size))  # target indexes\n",
        "    col = np.zeros((min_size))  # source indexes\n",
        "    ix = np.argsort(-x) + 1\n",
        "    #ix = np.argsort(-x) + 1\n",
        "    matched = 1\n",
        "    index = 1\n",
        "    while(matched <= min_size):\n",
        "        ipos = ix[index-1]\n",
        "        jc = int(np.ceil(ipos/m))\n",
        "        ic = ipos - (jc-1)*m\n",
        "        if ic == 0:\n",
        "            ic = 1\n",
        "            continue\n",
        "        if (used_rows[ic-1] == 0 and used_cols[jc-1] == 0):\n",
        "            row[matched-1] = ic - 1\n",
        "            col[matched-1] = jc - 1\n",
        "            max_list[matched-1] = x[index-1]\n",
        "            used_rows[ic-1] = 1\n",
        "            used_cols[jc-1] = 1\n",
        "            matched += 1\n",
        "        index += 1\n",
        "\n",
        "    result = np.zeros(S.T.shape)\n",
        "    for i in range(len(row)):\n",
        "        result[int(col[i]), int(row[i])] = 1\n",
        "    return result\n",
        "\n",
        "def get_statistics(alignment_matrix, groundtruth_matrix):\n",
        "    pred = greedy_match(alignment_matrix)\n",
        "    greedy_match_acc = compute_accuracy(pred, groundtruth_matrix)\n",
        "    # print(\"Accuracy: %.4f\" % greedy_match_acc)\n",
        "\n",
        "    #f1_score(pred, groundtruth_matrix, labels=[0, 1], pos_label=1, average='micro')\n",
        "    #MAP, AUC, Hit = compute_MAP_AUC_Hit(alignment_matrix, groundtruth_matrix)\n",
        "\n",
        "    #print(\"MAP: %.4f\" % MAP)\n",
        "    # print(\"AUC: %.4f\" % AUC)\n",
        "    #print(\"Hit-precision: %.4f\" % Hit)\n",
        "\n",
        "    pred_k(alignment_matrix,groundtruth_matrix,1)\n",
        "    pred_k(alignment_matrix,groundtruth_matrix,5)\n",
        "    pred_k(alignment_matrix,groundtruth_matrix,10)\n",
        "    pred_k(alignment_matrix,groundtruth_matrix,20)\n",
        "    pred_k(alignment_matrix,groundtruth_matrix,30)\n",
        "    pred_k(alignment_matrix,groundtruth_matrix,40)\n",
        "    pred_k(alignment_matrix,groundtruth_matrix,100)\n",
        "\n",
        "def compute_precision_k(top_k_matrix, gt):\n",
        "    n_matched = 0\n",
        "    gt_candidates = np.argmax(gt, axis = 1)\n",
        "    for i in range(gt.shape[0]):\n",
        "        if gt[i][gt_candidates[i]] == 1 and top_k_matrix[i][gt_candidates[i]] == 1:\n",
        "            n_matched += 1\n",
        "    n_nodes = (gt==1).sum()\n",
        "    return n_matched/n_nodes\n",
        "\n",
        "def compute_accuracy(greedy_matched, gt):\n",
        "    n_matched = 0\n",
        "    n_nodes = 0\n",
        "    #print(len(greedy_matched[1]))\n",
        "    #print(len(gt[1]))\n",
        "    for i in range(greedy_matched.shape[0]):\n",
        "        if greedy_matched[i].sum() > 0 and np.array_equal(greedy_matched[i], gt[i]):\n",
        "            n_matched += 1\n",
        "    # for i in range(gt.shape[0]):\n",
        "    #     if gt[i].sum()==1:\n",
        "    #         n_nodes +=1\n",
        "    n_nodes = (gt==1).sum()\n",
        "    return n_matched/n_nodes\n",
        "\n",
        "def compute_MAP_AUC_Hit(alignment_matrix, gt):\n",
        "    S_argsort = alignment_matrix.argsort(axis=1)[:, ::-1]\n",
        "    m = gt.shape[1] - 1\n",
        "    MAP = 0\n",
        "    AUC = 0\n",
        "    Hit = 0\n",
        "    for i in range(len(S_argsort)):\n",
        "        predicted_source_to_target = S_argsort[i]\n",
        "        # true_source_to_target = gt[i]\n",
        "        for j in range(gt.shape[1]):\n",
        "            if gt[i, j] == 1:\n",
        "                for k in range(len(predicted_source_to_target)):\n",
        "                    if predicted_source_to_target[k] == j:\n",
        "                        ra = k + 1\n",
        "                        MAP += 1/ra\n",
        "                        AUC += (m+1-ra)/m\n",
        "                        Hit += (m+2-ra)/(m+1)\n",
        "                        break\n",
        "                break\n",
        "    n_nodes = (gt==1).sum()\n",
        "    MAP /= n_nodes\n",
        "    AUC /= n_nodes\n",
        "    Hit /= n_nodes\n",
        "    return MAP, AUC, Hit\n",
        "\n",
        "def pred_k(alignment_matrix,groundtruth_matrix,k):\n",
        "    pred = top_k(alignment_matrix,k)\n",
        "    # print(top_k(alignment_matrix,k))/\n",
        "    pred_k = compute_precision_k(pred, groundtruth_matrix)\n",
        "    print(\"Precision_\"+str(k)+\": %.4f\" % pred_k)\n",
        "\n",
        "def top_k(S, k=1):\n",
        "    \"\"\"\n",
        "    S: scores, numpy array of shape (M, N) where M is the number of source nodes,\n",
        "        N is the number of target nodes\n",
        "    k: number of predicted elements to return\n",
        "    \"\"\"\n",
        "    top = np.argsort(-S)[:,:k]\n",
        "    # print(top)\n",
        "    result = np.zeros(S.shape)\n",
        "    for idx, target_elms in enumerate(top):\n",
        "        for elm in target_elms:\n",
        "            result[idx,elm] = 1\n",
        "    return result\n",
        "\n",
        "def LP_AUC(S,num_nodes,test_link):\n",
        "  num_edge = np.size(test_link,1)\n",
        "  negative_deges = negative_sampling(edge_index=test_link,num_nodes=num_nodes,num_neg_samples=num_edge)\n",
        "  pos_pro = torch.sum(S[test_link[0]]*S[test_link[1]],dim=1)\n",
        "  neg_pro = torch.sum(S[negative_deges[0]]*S[negative_deges[1]],dim=1)\n",
        "  pro = pos_pro-neg_pro\n",
        "  TP = len([i for i  in pro if i >=0])\n",
        "  FP = len(pro)-TP\n",
        "  print(f\"AUC:{(TP*1)/(TP+FP)}\")\n",
        "  return (TP*1)/(TP+FP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4b5y1PIcqXz"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "path = './cora_01.mat'\n",
        "epochs = 200\n",
        "learning_rate = 0.0001\n",
        "import scipy.io\n",
        "feature = scipy.io.loadmat(path)\n",
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "feature = h5py.File(path)\n",
        "# feature = scipy.io.laodmat(path)\n",
        "# train_matrix = load_mat(feature,'Train')\n",
        "# test_gt_matrix = load_mat(feature,'Test')\n",
        "train_matrix = load_mat(feature,'cora_train_01')\n",
        "test_gt_matrix = load_mat(feature,'cora_test_01')\n",
        "\n",
        "_,edge_train,_ = Get_edge_pyg(train_matrix)\n",
        "_,edge_test,_ = Get_edge_pyg(test_gt_matrix)\n",
        "graph = Data(x=train_matrix, edge_index = edge_train).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_JdAe4BpaGU"
      },
      "outputs": [],
      "source": [
        "#TODO:Two layer GCN\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "epochs = 200\n",
        "learning_rate = 0.001\n",
        "model = My_GCN(graph=graph).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[1000,1500,2000],gamma=0.1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model.forward()\n",
        "    loss,true_loss,neg_loss = model.loss(out)\n",
        "    print(f'epoch:{epoch:},Emd_loss={loss:.3},true_loss={true_loss:.3},neg_loss={neg_loss:.3}')\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "S = model.forward()\n",
        "S = torch.matmul(S,S.t())\n",
        "S = S.detach().cpu().numpy()\n",
        "get_statistics(S,test_gt_matrix)\n",
        "LP_AUC(torch.tensor(S),graph.num_nodes,edge_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E4R5HZhIFAc"
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "learning_rate = 0.001\n",
        "\n",
        "M = ['cora_M32']\n",
        "\n",
        "for name in M:\n",
        "  M = load_mat(feature,name)\n",
        "  _,edge_M_AW,M_att_AW = Get_edge_pyg(M+train_matrix)\n",
        "  graph_M_AW = Data(x=(M+train_matrix), edge_index = edge_M_AW, edge_attr = M_att_AW).to(device)\n",
        "  model = MD_GCN(sim_graph=graph,graph=graph_M_AW,dropout=0).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model.forward()\n",
        "    loss,true_loss,neg_loss = model.loss(out)\n",
        "    print(f'epoch:{epoch:},Emd_loss={loss:.3},true_loss={true_loss:.3},neg_loss={neg_loss:.3}')\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    del out,loss,true_loss,neg_loss\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  S = model.forward()\n",
        "  S = torch.matmul(S,S.t())\n",
        "  S = S.detach().cpu().numpy()\n",
        "  print(\"\\n\"+name+\"DGCN motif\")\n",
        "  get_statistics(S,test_gt_matrix)\n",
        "  LP_AUC(torch.tensor(S),graph.num_nodes,edge_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
